# ü§ñ AI Profile Matcher

‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ Python ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ CLIP (Contrastive Language-Image Pre-training) ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ß‡πà‡∏≤‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå (‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏û) ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à LIKE ‡∏´‡∏£‡∏∑‡∏≠ UNLIKE

## ‚ú® ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏´‡∏•‡∏±‡∏Å

- üß† ‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• CLIP ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
- ‚ö° ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á GPU (CUDA) ‡πÅ‡∏•‡∏∞ CPU (auto-detect)
- üìä ‡∏´‡∏•‡∏≤‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏û (mean, max, weighted_mean, top_k)
- üéØ ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Ñ‡πà‡∏≤ threshold ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
- üîß ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏ú‡πà‡∏≤‡∏ô environment variables ‡∏´‡∏£‡∏∑‡∏≠ command line
- üì± ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Unicode path (Windows/Unix)
- üóÇÔ∏è ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö batch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

## üîß ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á

### 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Virtual Environment

```bash
# ‡∏™‡∏£‡πâ‡∏≤‡∏á virtual environment
python -m venv .venv

# ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Windows)
.venv\Scripts\activate

# ‡πÄ‡∏õ‡∏¥‡∏î‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (Linux/Mac)
source .venv/bin/activate
```

### 2. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ

```bash
pip install -r requirements.txt
```

### 3. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Environment (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)

```bash
# ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
copy .env.example .env

# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env
```

## üöÄ ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

```bash
# ‡πÉ‡∏ä‡πâ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå default (./temp)
python src/main.py --prompt "‡∏™‡∏≤‡∏ß‡πÄ‡∏≠‡πÄ‡∏ä‡∏µ‡∏¢ ‡πÉ‡∏™‡πà‡πÅ‡∏ß‡πà‡∏ô ‡∏ú‡∏°‡∏¢‡∏≤‡∏ß"

# ‡∏£‡∏∞‡∏ö‡∏∏‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏≠‡∏á
python src/main.py --prompt "cute girl with glasses" --img_dir ./profiles/user123

# ‡∏õ‡∏£‡∏±‡∏ö threshold
python src/main.py --prompt "‡∏™‡∏≤‡∏ß‡∏™‡∏ß‡∏¢‡πÉ‡∏™" --threshold 0.3
```

### ‡πÇ‡∏´‡∏°‡∏î Interactive

```bash
python src/main.py --interactive --img_dir ./temp
```

### ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô

```bash
# ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
python src/main.py --prompt "‡∏™‡∏≤‡∏ß‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å" --method max

# ‡πÉ‡∏ä‡πâ weighted average
python src/main.py --prompt "‡∏™‡∏≤‡∏ß‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å" --method weighted_mean

# ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á top 3 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
python src/main.py --prompt "‡∏™‡∏≤‡∏ß‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å" --method top_k
```

### ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•

```bash
# ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏û
python src/main.py --prompt "‡∏™‡∏≤‡∏ß‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å" --show_all

# ‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏á‡∏µ‡∏¢‡∏ö (‡πÅ‡∏™‡∏î‡∏á‡πÅ‡∏Ñ‡πà‡∏ú‡∏•‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô)
python src/main.py --prompt "‡∏™‡∏≤‡∏ß‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å" --quiet

# ‡πÇ‡∏´‡∏°‡∏î verbose (‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°)
python src/main.py --prompt "‡∏™‡∏≤‡∏ß‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å" --verbose
```

## üìÅ ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ

```
ai_profile_matcher/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # Package initialization
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # CLI entry point
‚îÇ   ‚îú‚îÄ‚îÄ embedding.py         # CLIP text/image encoding
‚îÇ   ‚îú‚îÄ‚îÄ scorer.py            # Scoring and decision logic
‚îÇ   ‚îî‚îÄ‚îÄ utils.py             # Utility functions
‚îú‚îÄ‚îÄ temp/                    # ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏≠‡∏á)
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îú‚îÄ‚îÄ .env.example            # ‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
‚îî‚îÄ‚îÄ README.md               # ‡∏Ñ‡∏π‡πà‡∏°‡∏∑‡∏≠‡∏ô‡∏µ‡πâ
```

## ‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤

### Environment Variables (.env)

```env
# CLIP Model Configuration
MODEL_NAME=ViT-L-14        # ‡πÇ‡∏°‡πÄ‡∏î‡∏• CLIP ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
PRETRAINED=openai          # Pretrained weights

# Scoring Configuration  
THRESHOLD=0.25             # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô LIKE/UNLIKE
SCORE_METHOD=mean          # ‡∏ß‡∏¥‡∏ò‡∏µ‡∏£‡∏ß‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô

# Processing Configuration
BATCH_SIZE=32              # ‡∏Ç‡∏ô‡∏≤‡∏î batch ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•

# Logging Configuration
LOG_LEVEL=INFO             # ‡∏£‡∏∞‡∏î‡∏±‡∏ö logging
```

### ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (Score Methods)

- **mean**: ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏∏‡∏Å‡∏†‡∏≤‡∏û (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
- **max**: ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡πÉ‡∏î‡∏†‡∏≤‡∏û‡∏´‡∏ô‡∏∂‡πà‡∏á
- **weighted_mean**: ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å (‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏°‡∏≤‡∏Å‡∏Å‡∏±‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á)
- **top_k**: ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á top 3 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô

### ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ñ‡πà‡∏≤ Threshold

- **0.15-0.20**: ‡∏ú‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏ô (‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢)
- **0.25-0.30**: ‡∏™‡∏°‡∏î‡∏∏‡∏• (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)
- **0.35-0.40**: ‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏°‡∏≤‡∏Å)
- **0.45+**: ‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î‡∏°‡∏≤‡∏Å (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)

## üñºÔ∏è ‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û

### ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
- JPG/JPEG
- PNG  
- BMP
- GIF
- TIFF
- WebP

### ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
```
profiles/
‚îú‚îÄ‚îÄ user001/          # ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà 1
‚îÇ   ‚îú‚îÄ‚îÄ photo1.jpg
‚îÇ   ‚îú‚îÄ‚îÄ photo2.jpg
‚îÇ   ‚îî‚îÄ‚îÄ photo3.jpg
‚îú‚îÄ‚îÄ user002/          # ‡πÇ‡∏õ‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà 2
‚îÇ   ‚îú‚îÄ‚îÄ img1.png
‚îÇ   ‚îî‚îÄ‚îÄ img2.png
‚îî‚îÄ‚îÄ temp/             # ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    ‚îú‚îÄ‚îÄ pic1.jpg
    ‚îî‚îÄ‚îÄ pic2.jpg
```

## üìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

```
üéØ PROFILE EVALUATION RESULTS
============================================================

üëç DECISION: LIKE (confidence: HIGH)
üìä Profile Score: 0.3247
üéöÔ∏è  Threshold: 0.2500
üìà Method: mean

üìã STATISTICS:
   Images processed: 5
   Average similarity: 0.3247
   Best match: 0.4892
   Worst match: 0.1823
   Standard deviation: 0.1156

üñºÔ∏è  TOP 5 IMAGE SCORES:
--------------------------------------------------
‚≠ê photo1.jpg                    0.4892
‚≠ê photo3.jpg                    0.3841
‚≠ê photo2.jpg                    0.3245
üì∑ photo5.jpg                    0.2156
üì∑ photo4.jpg                    0.1823
```

## üîß ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á

### ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏û‡∏±‡∏í‡∏ô‡∏≤

```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á development dependencies (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)
pip install black isort flake8

# Format ‡πÇ‡∏Ñ‡πâ‡∏î
black src/
isort src/

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö style
flake8 src/
```

### ‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• CLIP ‡∏≠‡∏∑‡πà‡∏ô‡πÜ

‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô `.env`:
```env
MODEL_NAME=ViT-B-32    # ‡∏´‡∏£‡∏∑‡∏≠ ViT-L-14, RN50, RN101, etc.
PRETRAINED=openai      # ‡∏´‡∏£‡∏∑‡∏≠ laion2b_s34b_b79k, etc.
```

## üêõ ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤

### ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢

1. **CUDA Out of Memory**
   ```env
   BATCH_SIZE=16    # ‡∏•‡∏î‡∏Ç‡∏ô‡∏≤‡∏î batch
   ```

2. **‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÇ‡∏´‡∏•‡∏î‡∏ä‡πâ‡∏≤**
   - ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
   - ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏à‡∏∞‡πÄ‡∏£‡πá‡∏ß‡∏Ç‡∏∂‡πâ‡∏ô

3. **‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ**
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏µ‡∏¢‡∏´‡∏≤‡∏¢
   - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

### ‡∏Å‡∏≤‡∏£‡∏î‡∏π Log ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î

```bash
python src/main.py --prompt "test" --verbose
```

## üéì CLIP Training Pipeline

FinderPartner now includes a complete CLIP training pipeline for fine-tuning models on custom image-caption datasets.

### Prerequisites

```bash
# Check system requirements
python scripts/check_env.py
```

### Training Setup

1. **Prepare Your Dataset**
   
   Organize your data as follows:
   ```
   data/
   ‚îú‚îÄ‚îÄ images/
   ‚îÇ   ‚îú‚îÄ‚îÄ train/
   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ img001.jpg
   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ img002.jpg
   ‚îÇ   ‚îî‚îÄ‚îÄ val/
   ‚îÇ       ‚îú‚îÄ‚îÄ img001.jpg
   ‚îÇ       ‚îî‚îÄ‚îÄ img002.jpg
   ‚îú‚îÄ‚îÄ captions_train.csv
   ‚îî‚îÄ‚îÄ captions_val.csv
   ```
   
   CSV format: `filename,caption`
   ```csv
   filename,caption
   img001.jpg,Beautiful Asian woman with long hair
   img002.jpg,Young girl with glasses and bright smile
   ```

2. **Configure Training**
   
   Edit `configs/clip_base.yaml`:
   ```yaml
   # Model Configuration
   model_name: openai/clip-vit-base-patch32
   batch_size: 32  # Will auto-reduce if OOM
   epochs: 5
   lr: 5.0e-5
   
   # Data paths
   train_csv: data/captions_train.csv
   val_csv: data/captions_val.csv
   train_images_dir: data/images/train
   val_images_dir: data/images/val
   ```

3. **Start Training**
   
   ```bash
   # Basic training
   python src/train_clip.py --config configs/clip_base.yaml
   
   # Create sample data for testing
   python src/train_clip.py --create_sample_data
   
   # Resume from checkpoint
   python src/train_clip.py --config configs/clip_base.yaml --resume outputs/run_123/checkpoints/checkpoint-1000.pt
   ```

### Device Adaptation

The training pipeline automatically:
- ‚úÖ Detects CUDA availability (RTX 3060 12GB recommended)
- ‚úÖ Falls back to CPU if CUDA unavailable
- ‚úÖ Auto-reduces batch size on OOM
- ‚úÖ Uses mixed precision on GPU for memory efficiency

If you encounter memory issues:
```bash
# Force CPU training
CUDA_VISIBLE_DEVICES="" python src/train_clip.py --config configs/clip_base.yaml

# Or reduce batch size in config
batch_size: 16  # or even smaller
```

### Monitoring Training

- **W&B Integration**: Automatic logging to Weights & Biases
- **Local Logs**: Saved to `outputs/{run_name}/logs/`
- **Metrics**: Loss, retrieval R@1/5/10, similarity distributions

### Inference with Trained Model

```bash
# Use your trained model for inference
python src/main.py --model outputs/best_model --prompt "Your description"
```

### Optional Features

**ONNX Export:**
```bash
python export_clip.py --model_path outputs/best_model --output_dir outputs/onnx
```

**Gradio Demo:**
```bash
python gradio_demo.py --model_path outputs/best_model
```

**Run Tests:**
```bash
python tests/test_clip_smoke.py
```

## üìä Training Results

After successful training, you'll find:
- `outputs/{run_name}/best_model/` - Best performing model
- `outputs/{run_name}/final_model/` - Final epoch model  
- `outputs/{run_name}/checkpoints/` - Training checkpoints
- `outputs/{run_name}/metrics_history.json` - Training metrics

## üìù TODO / ‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏ï‡πà‡∏≠

- [x] ‚úÖ CLIP Training Pipeline
- [x] ‚úÖ ONNX Export Support
- [x] ‚úÖ Gradio Web Interface
- [x] ‚úÖ Automatic Device Detection
- [x] ‚úÖ Mixed Precision Training
- [ ] ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö video files
- [ ] Database integration
- [ ] Multi-language prompts optimization
- [ ] Distributed training support
- [ ] Docker containerization

## ü§ù ‡∏Å‡∏≤‡∏£‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡∏£‡πà‡∏ß‡∏°

1. Fork ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ
2. ‡∏™‡∏£‡πâ‡∏≤‡∏á feature branch
3. Commit ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á
4. Push ‡πÑ‡∏õ‡∏¢‡∏±‡∏á branch
5. ‡∏™‡∏£‡πâ‡∏≤‡∏á Pull Request

## üìÑ License

‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô open source ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß

---

Made with ‚ù§Ô∏è by AI Developer
